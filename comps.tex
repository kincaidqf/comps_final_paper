\documentclass[10pt,twocolumn]{article}

% use the oxycomps style file
\usepackage{oxycomps}

% usage: \fixme[comments describing issue]{text to be fixed}
% define \fixme as not doing anything special
\newcommand{\fixme}[2][]{#2}
% overwrite it so it shows up as red
\renewcommand{\fixme}[2][]{\textcolor{red}{#2}}
% overwrite it again so related text shows as footnotes
%\renewcommand{\fixme}[2][]{\textcolor{red}{#2\footnote{#1}}}

\bibliography{references.bib}

% include metadata in the generated pdf file
\pdfinfo{
    /Title (TimeGAN Optimization on Small Datasets: Generating and Evaluating Synthetic Macroeconomic Time Series)
    /Author (Kincaid Fries)
}

% set the title and author information
\title{TimeGAN Optimization on Small Datasets: Generating and Evaluating Synthetic Macroeconomic Time Series}
\author{Kincaid Fries}
\affiliation{Occidental College}
\email{kfries@oxy.edu}

\begin{document}

\maketitle

\section{Introduction}

\subsection{Background}
The use of machine learning in financial prediction has grown rapidly due to its ability to model complex, multivariable relationships and generate realistic predictions. Machine learning is particularly effective in equities markets where thousands of points of training data are available daily for stock movements. In contrast, macroeconomic data takes months of study, surveying, and research to come up with even a single realistic measurement. Consequently, macroeconomic forecasting models rely on quarterly historical data at best. \textcite{baltazar2020sustainableeconomies} note that small datasets affect the reliability of macroeconomic modelling. Other challenges like changes in calculation methods, unavailability of data for certain time periods, and changes in indicator definitions make it hard to train macroeconomic models without overfitting to small datasets. Recent advances in synthetic data generation offer a promising alternative, allowing researchers to create realistic simulations of economic behavior without relying solely on historical data.

\subsection{Goal}
The goal of my senior comprehensive project is to evaluate whether a machine learning model trained on small macroeconomic datasets can be used to generate realistic synthetic time series. By normalizing macroeconomic indicators across different economies, I hope to address the issue of relatively limited time-series for a single country by taking training data from multiple countries. My project will explore whether synthetic time-series produced by a model trained on data from multiple countries could potentially address the problem of lack of data availability, and serve as a valid counterpart to real economic data in forecasting applications.

Abstracting from this project, data availability is becoming an increasingly prevalent issue as the technological world embraces machine learning. Major data companies like Meta and OpenAI have faced lawsuits over data piracy, and smaller companies want to utilize the power of machine learning to drive decision making, but may face issues with security or compliance that prevent them from training models. If we had the power to take a small dataset and extend it, or create realistic alternative datasets using synthetic data generation, then a number of these problems could be solved. Security, privacy, and copyright could be better preserved while still having access to the quantity of data needed to train machine learning models. 

\subsection{Approach}
I will implement a TimeGAN model, which combines a supervised autoencoder to learn temporal dynamics with a generative adversarial network (GAN) to generate realistic synthetic data [CITATION NEEDED]. The model will be trained using macroeconomic data taken from developed, free-market economies, to ensure there is consistency in the underlying macroeconomic trends it identifies. To evaluate whether the generated synthetic data is realistic, I will compare the properties of the synthetic data with real world data using a number of statistical tests focused on distributional similarity, cross time similarity, and novelty. Additionally, I will examine the performance of a forecasting model using the train-synthetic test-real (TSTR) method–training a simple forecasting model on the synthetic data to predict the next step in the real data. Through TSTR evaluation I will be able to assess the potential viability of using synthetic data in training models for real data tasks.

By looking at both statistical factors and forecasting model performance, I hope to have a comprehensive framework for assessing the viability of the synthetic data. I will then iterate over the model, adjusting training parameters in order to see what areas are particularly effective for model optimization on small datasets.

\section{Technical Background}

\section{Prior Work}

First and foremost, my project relies heavily on the original TimeGAN implementation by \textcite{yoon2019timeseriesgenerative}. They identify that on their own, GANs “do not adequately attend to the temporal correlations unique to time-series data”, while purely supervised models are “inherently deterministic” (\textcite{yoon2019timeseriesgenerative}, 1). Their proposal for addressing this disparity was to create an interwoven framework that provides both the benefits of supervised models and the adversarial component of GANs. However, \textcite{yoon2019timeseriesgenerative} are not the only researchers who aim to optimize the performance of a GAN across temporal features. The unique aspect of their project that stood out to me was the fact that the model is trained on batches of data which is ideal for training the model on macroeconomic conditions using multiple different countries for input. 

Aside from the original TimeGAN repository, my project draws inspiration from studies that reflect the technical, theoretical, and evaluative aspects of synthetic data generation and machine learning applications in economics. The first applies GANs to generating synthetic financial scenarios (\textcite{rizzato2023generativeadversarial}). Another applies a macroeconomic model to loan default rate predictions (\textcite{baltazar2020sustainableeconomies}). Finally, \textcite{yuan2024multifacetedevaluation} and \textcite{livieris2024anevaluationframework} provide a reference for how to go about my evaluation metrics and results discussion.

\subsection{Generative Adversarial Networks Applied to Synthetic Financial Scenarios Generation}
\textcite{rizzato2023generativeadversarial} propose a new generative adversarial network approach to synthetic financial scenario generation, which they call Jinkou. Jinkou was made to generate realistic synthetic time series datasets on the movement of equities under different macroeconomic conditions \cite{rizzato2023generativeadversarial}. Unlike the original TimeGAN paper, they introduce a macroeconomic element which offers a similar conceptual approach and methodology to my own goals for this project. 

\subsubsection{Technical Approach}
They first took real datasets on equities with specific variables related to stock performance, and augmented that dataset with global state variables describing macroeconomic conditions \cite{rizzato2023generativeadversarial}. Their proprietary Jinkou method uses a combination of a bidirectional GAN (BiGAN) and conditional GAN (cGAN) to improve the probability distribution of the synthetic data \cite{rizzato2023generativeadversarial}. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{bigan_vs_cgan.png}
    \caption{Visual comparison of BiGAN and Conditional GAN training architectures. Adapted from \textcite{rizzato2023generativeadversarial}.}
    \label{fig:bigan-vs-cgan}
\end{figure}

The BiGAN maps latent space to the data space with an autoencoder, similar to the embedder and recovery networks of the TimeGAN. The synthetic time series generated by the trained BiGAN are used as the input for the cGAN, which learns to map each datapoint \textit{y} to a probability score \textit{p} drawn from the dataset distribution of \textit{P} \cite{rizzato2023generativeadversarial}. The cGAN refines the results of the BiGAN by more accurately mapping the data to the probability distribution expected of the data. They perform statistical analysis of their synthetic data generated under four different market conditions (bull market, bear market, volatile market, and debt crisis). They evaluated the synthetic change in stock price from start to end of the time series with the real percent change in stock price \cite{rizzato2023generativeadversarial}. They found similar values for synthetic vs real data, typically with a difference between [-1,2]\%, indicating that their synthetic data was sufficiently accurate to the real data.

\subsubsection{Key Takeaway}
This project demonstrates how synthetic data is a viable way of simulating market scenarios under different macroeconomic conditions. Specific to my project, \textcite{rizzato2023generativeadversarial} found the use of GAN models to be effective for generating synthetic time-series, and were able to compare that synthetic data to real data with a satisfactory degree of accuracy. Their results validate the importance of macroeconomic indicators in financial modelling.

\section{Methods}

\section{Evaluation Metrics}

\section{Results and Discussion}

\section{Ethical Considerations}

\section{Conclusion and Future Work}

% Defer appendix material until after the bibliography so the bibliography
% appears as part of the main paper and the following sections become Appendix.
\AtEndDocument{%
    \clearpage
    \appendix
    \section{Replication Instructions}
    \section{Architecture Overview}
}

\printbibliography

\clearpage

\onecolumn

\end{document}